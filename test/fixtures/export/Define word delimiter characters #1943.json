{
  "config": {
    "id": "36a3b0b5-bad0-4a04-b79b-441c7cef77db",
    "label": "BetterBibTeX JSON",
    "localeDateOrder": "dmy",
    "options": {
      "exportNotes": false
    },
    "preferences": {
      "citekeyFormat": "authorsn(n=1,creator=\"*\",initials=false,sep=\"-\").fold.lower + \"-\" + year + \"-\" + Title.replace(find=\"-\",replace=\" \").skipwords.select(1,1).lower",
      "warnBulkModify": 0
    }
  },
  "items": [
    {
      "DOI": "10/ggd754",
      "abstractNote": "We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We chose the Transformers for our analysis as they have been shown effective with various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and observe that the choice of the objective determines this process. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.",
      "accessDate": "2021-10-05T09:58:46Z",
      "citationKey": "voita-etal-2019-bottomup",
      "conferenceName": "EMNLP-IJCNLP 2019",
      "creators": [
        {
          "creatorType": "author",
          "firstName": "Elena",
          "lastName": "Voita"
        },
        {
          "creatorType": "author",
          "firstName": "Rico",
          "lastName": "Sennrich"
        },
        {
          "creatorType": "author",
          "firstName": "Ivan",
          "lastName": "Titov"
        }
      ],
      "date": "2019-11",
      "itemID": 1,
      "itemType": "conferencePaper",
      "libraryCatalog": "ACLWeb",
      "notes": [
        "<p><strong>TL;DR:</strong></p>\n<p>The task a Transformer is trained to solve influence the nature of the representation learnt (expected, but good thing to be able to demonstrate it experimentally).</p>\n<p>In MLM, MI first decreases and then increases in the encoder layer (expected as the goal is to reconstruct the mask word, contextual information is needed). For LM and MT, MI decreases as the information flows through the layers.</p>\n<p>For MLM, token representation is heavily influenced by it's frequency. Infrequent tokens change more are they flow through the layers. Whereas for MT and LM, frequent tokens change more than infrequent ones.</p>\n<p>For MLM, infrequent tokens influence the representation of frequent tokens whereas this is not the case for MT and LM.</p>\n<p>Regarding token identity, this information is extremely well preserved for MLM, well preserved for MT, and not preserved at all for LM (as the goal is to predict the next token)</p>\n<p>Token position gets lost for MLM, but is better preserved for MT and LM (as their task requires to have information about the position of a given token).</p>\n<p><strong>Annotations extraites (05/10/2021 Ã  11:37:32)</strong></p>\n<p>\"We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"the representations learned by the Transformer differ significantly depending on the objective.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"how information flows across Transformer layers and how this process depends on the choice of learning objective.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"One popular approach for analyzing representations of neural models is to evaluate how informative they are for various linguistic tasks, so-called \"probing tasks\"\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"we characterize how the learning objective determines the information flow in the model\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"we consider how the representations of individual tokens in the Transformer evolve between layers under different learning objectives.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"Tishby and Zaslavsky ( 2015 ) state that \"the goal of any supervised learning is to capture and efficiently represent the relevant information in the input variable about the output-label variable\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=1\">Voita-etal 2019:1</a>)</p>\n<p>\"The Transformer encodes a sentence by iteratively updating representations associated with each token starting from a context-agnostic representation consisting of a positional and a token embedding.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=2\">Voita-etal 2019:2</a>)</p>\n<p>\"At each layer token representations exchange information among themselves via multi-head attention and then this information is propagated to the next layer via a feed-forward transformation.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=2\">Voita-etal 2019:2</a>)</p>\n<p>\"we study which type of information gets lost and gained in the interactions between\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=2\">Voita-etal 2019:2</a>)</p>\n<p>\"tokens and to what extent a certain property is important for defining a token representation at each layer and for each task.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=2\">Voita-etal 2019:2</a>)</p>\n<p>\"(1) with the LM objective, as you go from bottom to top layers, information about the past gets lost and predictions about the future get formed\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=2\">Voita-etal 2019:2</a>)</p>\n<p>\"(2) for MLMs, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation; the token identity then gets recreated at the top layer;\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=2\">Voita-etal 2019:2</a>)</p>\n<p>\"The IB method ( Tishby et al. , 1999 ) considers a joint distribution of input-output pairs p ( X; Y ) and aims to extract a compressed representation ~X for an input X such that ~X retains as much as possible information about the output Y . More formally, the IB method maximizes the mutual information (MI) with the output I ( ~X ; Y ) , while penalizing for MI with the input I ( ~X ; X ) . The latter term in the objective ensures that the representation is indeed a compression.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=3\">Voita-etal 2019:3</a>)</p>\n<p>\"To estimate MI, we need to consider token representations at a layer as samples from a discrete distribution\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"To get such distribution, in the original works ( ShwartzZiv and Tishby , 2017 ), the authors binned the neuron's arctan activations.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"Instead, similarly to Sajjadi et al. ( 2018 ), we discretize the representations by clustering them into a large number of clusters. Then we use cluster labels instead of the continuous representations in the MI estimator\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"First, we estimate the MI between an input token and a representation of this token at each layer.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"For MLM, only tokens replaced at random are considered to get examples where input and output are different.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\",\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"For LM, the amount of relevant information about the current input token decreases.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"MT shows a similar behavior, but the decrease is much less sharp.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"The most interesting and surprising graph is for MLM: first, similarly to other models, the information about the input token is getting lost but then, at two top layers, it gets recovered.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"it suggests that this extra information is obtained from other tokens in the context.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"We can see that, as expected, MI with input tokens\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=4\">Voita-etal 2019:4</a>)</p>\n<p>\"decreases while MI with output tokens increases.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=5\">Voita-etal 2019:5</a>)</p>\n<p>\"we observed monotonic behavior of LM, when looking at the information with both input and output tokens, we can see the two processes, losing information about input and accumulating information about output, for both LM and MLM models.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=5\">Voita-etal 2019:5</a>)</p>\n<p>\"In this section, we analyze the flow of information.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=5\">Voita-etal 2019:5</a>)</p>\n<p>\"how much processing is happening in a given layer; which tokens influence other tokens most; which tokens gain most information from other tokens.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=5\">Voita-etal 2019:5</a>)</p>\n<p>\"CCA is a multivariate statistical method for relating two sets of observations arising from an underlying process.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=5\">Voita-etal 2019:5</a>)</p>\n<p>\"The values of PWCCA range from 0 to 1, with 1 indicating that the observations are linear transformations of each other, 0 indicating no correlation.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=5\">Voita-etal 2019:5</a>)</p>\n<p>\"differences due to training objective are much larger than the ones due to random initialization of a model.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"MT and MLM objectives produce representations that are closer to each other than to LM's representations.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"In this section, we select tokens with some predefined property (e.g., frequency) and investigate how much the tokens are influenced by other\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"Amount of change. We measure the extent of change for a group of tokens as the PWCCA distance between the representations of these tokens\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"Influence. To measure the influence of a token at l th layer on other tokens, we measure PWCCA distance between two versions of representations of other tokens in a sentence: first after encoding as usual, second when enco\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"Frequent tokens change more than rare ones in all layers in both LM and MT.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"We can speculate that top layers focus on predicting the future rather than incorporating the past, and, at that stage, token frequency of the last observed token becomes less important.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"The behavior for MLM is quite different.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"The transition from a generalized token representation, formed at the encoding stage, to recreating token identity apparently requires more changes for rare tokens.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"When measuring influence, we find that rare tokens generally influence more than frequent ones (Figure 5 ).\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=6\">Voita-etal 2019:6</a>)</p>\n<p>\"importance of CCG tag for MLM degrades at higher layers. This agrees with the work by Tenney et al. ( 2019a ). The authors observe that for different tasks (e.g., part-of-speech, constituents, dependencies, semantic role labeling, coreference) the contribution 6 of a layer to a task increases up to a certain layer, but then decreases at the top layers.\" (<a href=\"zotero://open-pdf/library/items/2JU26MQ7?page=9\">Voita-etal 2019:9</a>)</p>"
      ],
      "pages": "4396â4406",
      "place": "Hong Kong, China",
      "publicationTitle": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "publisher": "Association for Computational Linguistics",
      "shortTitle": "The Bottom-up Evolution of Representations in the Transformer",
      "title": "The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives",
      "url": "https://aclanthology.org/D19-1448"
    }
  ]
}